---
phase: 04-mcp-server
plan: 05
type: execute
wave: 5
depends_on: [04-01, 04-02, 04-03, 04-04]
files_modified:
  - mcp_server.py
  - main.py
  - Dockerfile
  - README.md
autonomous: true

must_haves:
  truths:
    - "Single Python process runs both Flask REST API and FastMCP server"
    - "Flask runs on port 5000, MCP server runs on port 8000"
    - "Both servers can be started with 'python main.py'"
    - "Deployment to Railway uses HTTP transport for MCP (not stdio)"
    - "Health check endpoints exist for both Flask (/: home page, /health) and MCP (/health)"
    - "Documentation explains how to run both servers"
    - "MCP endpoint is accessible at http://localhost:8000/mcp"
    - "Flask API remains accessible at http://localhost:5000"
  artifacts:
    - path: "main.py"
      provides: "Dual-server startup script"
      exports: ["main execution block"]
      min_lines: 20
    - path: "mcp_server.py"
      provides: "ASGI app for production deployment"
      exports: ["create_mcp_app", "mcp.asgi_app"]
      min_lines: 5
    - path: "Dockerfile"
      provides: "Container configuration for Railway deployment"
      contains: "CMD|ENTRYPOINT"
    - path: "README.md"
      provides: "Documentation for running both servers"
      contains: "MCP|Model Context Protocol"
  key_links:
    - from: "main.py"
      to: "Flask app"
      via: "import app module"
      pattern: "import app|from app import"
    - from: "main.py"
      to: "MCP server"
      via: "subprocess or threading"
      pattern: "Thread|subprocess|start.*mcp"
    - from: "Dockerfile"
      to: "both servers"
      via: "CMD or ENTRYPOINT instruction"
      pattern: "python.*main\\.py"
---

<objective>
Configure dual-server architecture where Flask REST API and FastMCP server run in a single Python process for production deployment.

Purpose: Enable Railway deployment with both REST and MCP interfaces accessible through standard HTTP ports, eliminating the need for separate processes.
Output: Single-process deployment serving Flask (port 5000) and FastMCP (port 8000) with health checks and production-ready configuration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-mcp-server/04-CONTEXT.md
@main.py
@.planning/phases/04-mcp-server/04-01-SUMMARY.md
@.planning/phases/04-mcp-server/04-02-SUMMARY.md
@.planning/phases/04-mcp-server/04-03-SUMMARY.md
@.planning/phases/04-mcp-server/04-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Update mcp_server.py to expose ASGI app for production</name>
  <files>mcp_server.py</files>
  <action>
    Update mcp_server.py to support both development (standalone) and production (ASGI app) modes:

    1. Modify the if __name__ == "__main__" block:
       - Keep existing mcp.run(transport="http", host="0.0.0.0", port=8000) for standalone use
       - Add comment: "# For standalone development: python mcp_server.py"
    2. Ensure create_mcp_app() function exists (should already be there from 04-01):
       - Returns mcp.asgi_app or mcp.http_app() (check FastMCP documentation)
       - This allows mounting in production ASGI servers like Uvicorn
    3. Add a health check route if not already present:
       - @mcp.custom_route("/health", methods=["GET"])
       - Returns PlainTextResponse("OK")

    This ensures the MCP server can run:
    - Standalone: python mcp_server.py (for development)
    - Embedded: via create_mcp_app() (for production with Flask)

    The ASGI app approach is critical for Railway deployment where a single process must serve both interfaces.
  </action>
  <verify>grep -q "def create_mcp_app" mcp_server.py && grep -q "asgi_app\|http_app" mcp_server.py</verify>
  <done>mcp_server.py exposes ASGI app via create_mcp_app() for production embedding</done>
</task>

<task type="auto">
  <name>Update main.py to run both Flask and MCP servers</name>
  <files>main.py</files>
  <action>
    Update main.py to run both Flask REST API (port 5000) and FastMCP server (port 8000) in a single process:

    1. Import threading and the MCP server's ASGI app
    2. Add import: from mcp_server import create_mcp_app
    3. Add import: import uvicorn
    4. Create a function run_mcp_server() that:
       - Gets the MCP ASGI app: mcp_app = create_mcp_app()
       - Runs uvicorn in a thread: uvicorn.run(mcp_app, host="0.0.0.0", port=8000, log_level="info")
    5. In the main execution block (after app.run()):
       - Create a Thread for the MCP server: mcp_thread = threading.Thread(target=run_mcp_server, daemon=True)
       - Start the MCP thread: mcp_thread.start()
       - Then run Flask: app.run(host="0.0.0.0", port=5000)
    6. Add health check endpoint to Flask if not present:
       - @app.route('/health')
       - Returns jsonify({"status": "ok", "flask": "running", "mcp": "http://localhost:8000/mcp"})

    This ensures both servers start together:
    - Flask API: http://localhost:5000 (REST endpoints)
    - MCP server: http://localhost:8000/mcp (MCP protocol)
    - Flask health: http://localhost:5000/health
    - MCP health: http://localhost:8000/health

    Note: uvicorn may need to be added to requirements.txt if not already present.
  </action>
  <verify>grep -q "threading" main.py && grep -q "mcp_server\|create_mcp_app" main.py && grep -q "uvicorn" main.py</verify>
  <done>main.py starts both Flask (port 5000) and MCP (port 8000) servers in a single process using threading</done>
</task>

<task type="auto">
  <name>Add uvicorn to requirements.txt</name>
  <files>requirements.txt</files>
  <action>
    Add `uvicorn>=0.24.0` to requirements.txt on a new line at the end of the file.

    Uvicorn is required to run the FastMCP ASGI app. It's a lightning-fast ASGI server that supports HTTP/1.1, WebSockets, and the Streamable HTTP protocol used by FastMCP.

    Place the line after the `fastmcp>=3.0.0` line.
  </action>
  <verify>grep -q "uvicorn" requirements.txt</verify>
  <done>requirements.txt includes uvicorn>=0.24.0 for running ASGI app</done>
</task>

<task type="auto">
  <name>Update Dockerfile for dual-server deployment</name>
  <files>Dockerfile</files>
  <action>
    Update Dockerfile to ensure both Flask and MCP servers are available:

    1. Check that the CMD or ENTRYPOINT runs main.py (which now starts both servers)
    2. If Dockerfile runs `python app.py` directly, change to `python main.py`
    3. Ensure port 8000 is exposed alongside port 5000 (or use EXPOSE 5000 8000)
    4. Add health check if not present: HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 CMD curl -f http://localhost:5000/health || exit 1

    The Dockerfile should already be configured for Railway, but verify it:
    - Uses python:3.11-slim or similar base image
    - Installs requirements.txt
    - Runs main.py (not app.py directly)
    - Exposes both ports 5000 and 8000 (or uses Railway's PORT env var for Flask, hardcode 8000 for MCP)

    For Railway specifically:
    - Railway sets PORT env var dynamically
    - Flask should use os.environ.get('PORT', 5000) for its port
    - MCP server should stay on port 8000 (internal service)
  </action>
  <verify>grep -q "main.py" Dockerfile</verify>
  <done>Dockerfile runs main.py which starts both Flask and MCP servers</done>
</task>

<task type="auto">
  <name>Update README.md with MCP server documentation</name>
  <files>README.md</files>
  <action>
    Add a new section to README.md documenting the MCP server:

    Add after the existing API endpoints section:

    ## MCP Server

    This project includes a Model Context Protocol (MCP) server for AI agent integration.

    **Running the servers:**

    ```bash
    # Start both Flask API and MCP server
    python main.py
    ```

    This starts:
    - Flask REST API: http://localhost:5000
    - MCP Server: http://localhost:8000/mcp

    **MCP Tools:**

    1. **analyze_video** - Fetch complete YouTube video data (transcript, metadata, statistics, comments)
       - Accepts: video URL or ID
       - Returns: Full data bundle with graceful degradation

    2. **search_youtube_content** - Search YouTube videos by keyword
       - Accepts: search query, max_results (default 10)
       - Warning: Expensive (100 YouTube API quota units)

    3. **get_channel_overview** - Fetch channel info and recent uploads
       - Accepts: channel URL or ID, max_uploads (default 10)
       - Returns: Channel metadata + recent videos

    **Health Checks:**

    - Flask: http://localhost:5000/health
    - MCP: http://localhost:8000/health

    **Integration:**

    Use these MCP tools from n8n or other MCP-compatible platforms to integrate YouTube data into AI workflows.

    This provides clear documentation for users wanting to use the MCP interface.
  </action>
  <verify>grep -q "MCP Server\|Model Context Protocol" README.md</verify>
  <done>README.md documents MCP server, available tools, health checks, and usage instructions</done>
</task>

<task type="auto">
  <name>Add Flask health check endpoint</name>
  <files>app.py</files>
  <action>
    Add a health check endpoint to app.py if not already present:

    1. Add route after the existing routes:
       @app.route('/health')
       def health():
           return jsonify({
               "status": "ok",
               "service": "YouTube Data Fetcher API",
               "flask": "running",
               "mcp": "http://localhost:8000/mcp"
           })

    This provides a simple health check for the Flask API that also indicates where the MCP server is running.

    Place this route before the error handler (before line 510 in current app.py).
  </action>
  <verify>grep -q "'/health'" app.py</verify>
  <done>app.py has /health endpoint returning service status</done>
</task>

</tasks>

<verification>
After completion, verify:
1. `python main.py` starts both servers (check logs for Flask and MCP startup messages)
2. Flask health check: `curl http://localhost:5000/health` returns JSON with status "ok"
3. MCP health check: `curl http://localhost:8000/health` returns "OK"
4. Flask API still works: `curl http://localhost:5000/api/transcript/dQw4w9WgXcQ` returns transcript
5. MCP tools accessible: `curl http://localhost:8000/mcp/tools/list` returns all 3 tools
6. Both servers log to console without errors
7. README.md documents the MCP server clearly
</verification>

<success_criteria>
1. Single python main.py command starts both Flask (port 5000) and MCP (port 8000) servers
2. Flask API endpoints continue working without any changes
3. MCP server is accessible via HTTP transport at /mcp endpoint
4. Health check endpoints exist for both services
5. Dockerfile is configured for Railway deployment
6. Documentation explains how to run and use both interfaces
7. No port conflicts between Flask (5000) and MCP (8000)
8. Both servers run in same process/container (critical for Railway deployment)
</success_criteria>

<output>
After completion, create `.planning/phases/04-mcp-server/04-05-SUMMARY.md` with:
- Dual-server architecture details (threading approach, ports)
- Deployment configuration for Railway
- Health check endpoints for both services
- Documentation updates
- Test results confirming both servers work together
- Phase 4 completion summary (all 5 plans complete, all 3 MCP tools implemented)
</output>
